{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import weighted\n",
    "\n",
    "from jre_utils.datapath import DATA_DIRECTORY_PATH\n",
    "from jp_prefecture.address import JpAddressParser\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/core_scraped/lpa/2022.csv\n",
      "../../data/pre_derived_lpa/yearly/2022.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Goal: \n",
    "For the LPA data, \n",
    "index by year, prefecture and municipality, then\n",
    "get the weighted average price per unit area\n",
    "DONE!!\n",
    "\"\"\"\n",
    "\n",
    "lpa_data_path = f\"{DATA_DIRECTORY_PATH}/core_scraped/lpa\"\n",
    "lpa_data_paths = {\n",
    "    year: f\"{lpa_data_path}/{year}.csv\"\n",
    "    for year in range(1971, 2024)\n",
    "}\n",
    "print(lpa_data_paths[2022])\n",
    "\n",
    "lpa_pre_derived_data_path = f\"{DATA_DIRECTORY_PATH}/pre_derived_lpa\"\n",
    "lpa_pre_derived_data_paths = {\n",
    "    year: f\"{lpa_pre_derived_data_path}/yearly/{year}.csv\"\n",
    "    for year in range(1971, 2024)\n",
    "}\n",
    "print(lpa_pre_derived_data_paths[2022])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert address to city code\n",
    "addr_column = \"所在及び地番\"\n",
    "price_per_unit_area_column = \"価格(円/m²)\"\n",
    "area_column = \"地積(m²)\"\n",
    "\n",
    "required_columns = [\"year\", \"area_code\", \"area\", \"unit_price\", \"traded_area\", \"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E.g. Maps 1101 to 1100'\n",
      "'E.g. Maps 1100 to Hokkaido Sapporo-shi'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "sub_city_to_city_path = f\"{DATA_DIRECTORY_PATH}/core_scraped/sub_city_to_city.json\"\n",
    "with open(sub_city_to_city_path) as fd:\n",
    "     sub_city_to_city = json.load(fd)\n",
    "     pprint(f\"E.g. Maps 1101 to {sub_city_to_city[\"1101\"]}\")\n",
    "\n",
    "area_code_to_area_path = f\"{DATA_DIRECTORY_PATH}/core_scraped/area_code_to_area.json\"\n",
    "with open(area_code_to_area_path) as fd:\n",
    "     area_code_to_area = json.load(fd)\n",
    "     pprint(f\"E.g. Maps 1100 to {area_code_to_area[\"1100\"]}\") \n",
    "\n",
    "def get_area_from_area_code(area_code):\n",
    "     return area_code_to_area.get(area_code, \"na\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_area_column(area):\n",
    "    try:\n",
    "        return int(area.split(\"(\")[0].replace(\",\", \"\"))\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        return np.NaN\n",
    "\n",
    "def get_city_code(parser, addr):\n",
    "    try:\n",
    "        city_code = str(parser.parse_address(addr).cityCode)\n",
    "        return sub_city_to_city.get(city_code, city_code)\n",
    "    except:\n",
    "        return addr\n",
    "\n",
    "def get_area_from_area_code(area_code):\n",
    "     return area_code_to_area.get(area_code, \"na\" )\n",
    "\n",
    "parser = JpAddressParser(enable_town=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_aggregate(x):\n",
    "    d = {}\n",
    "    d[\"unit_price_wmean\"] = np.average(x[\"unit_price\"], weights=x[\"traded_area\"])\n",
    "    d[\"unit_price_wmedian\"] = weighted.median(x[\"unit_price\"], weights=x[\"traded_area\"])\n",
    "    d[\"unit_price_mean\"] = x[\"unit_price\"].mean()\n",
    "    d[\"unit_price_median\"] = x[\"unit_price\"].median()\n",
    "    d[\"total_traded_area\"] = x[\"traded_area\"].sum()\n",
    "    d[\"count\"] = x[\"count\"].count()\n",
    "    return pd.Series(\n",
    "        d,\n",
    "        index=[\n",
    "            \"unit_price_wmean\",\n",
    "            \"unit_price_wmedian\",\n",
    "            \"unit_price_mean\",\n",
    "            \"unit_price_median\",\n",
    "            \"total_traded_area\",\n",
    "            \"count\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "for year, data_path in lpa_data_paths.items():\n",
    "    # main_df = pd.read_csv(data_path)\n",
    "    main_df = main_df.assign(year=year, count=1)\n",
    "    main_df[\"area_code\"] = main_df[addr_column].apply(lambda x: get_city_code(parser, x))\n",
    "    main_df[\"area\"] = main_df[\"area_code\"].apply(get_area_from_area_code)\n",
    "    main_df[\"unit_price\"] = main_df[price_per_unit_area_column].apply(prepare_area_column)\n",
    "    main_df[\"traded_area\"] = main_df[area_column].apply(prepare_area_column)\n",
    "    main_df = main_df[main_df[\"area_code\"].apply(lambda x: x.isdigit())]\n",
    "    main_df.to_csv(f\"{DATA_DIRECTORY_PATH}/pre_derived_lpa/yearly/{year}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/53 [00:19<?, ?it/s]\n",
      "100%|██████████| 53/53 [00:18<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "\n",
    "pbar = tqdm(total=len(lpa_pre_derived_data_paths))\n",
    "\n",
    "for year, data_path in lpa_pre_derived_data_paths.items():\n",
    "    main_df = pd.read_csv(data_path)\n",
    "    df = main_df[required_columns]\n",
    "    df = (\n",
    "        df.groupby([\"year\", \"area_code\", \"area\"])\n",
    "        .apply(custom_aggregate)\n",
    "        .reset_index()\n",
    "    )\n",
    "    df = df.sort_values(by=[\"year\", \"area_code\"], ascending=[False, True]).reset_index(drop=True)\n",
    "    df.to_csv(f\"{DATA_DIRECTORY_PATH}/derived_lpa/yearly/{year}.csv\", index=False)\n",
    "    final_df = pd.concat([final_df, df])\n",
    "    \n",
    "    pbar.update()\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(f\"{DATA_DIRECTORY_PATH}/derived_lpa/combined.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
