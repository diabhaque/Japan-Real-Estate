{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from jre_utils.datapath import (\n",
    "    factor_data_paths,\n",
    "    get_derived_csv_path,\n",
    "    get_derived_lpa_path,\n",
    "    get_derived_plps_path,\n",
    "    DATA_DIRECTORY_PATH\n",
    ")\n",
    "from jre_utils.config import asset_types\n",
    "from jre_utils.visualize import plot_time_series\n",
    "\n",
    "from jp_prefecture.jp_cities import jp_cities as jp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E.g. Maps 1100 to Hokkaido Sapporo-shi\n"
     ]
    }
   ],
   "source": [
    "area_code_to_area_path = f\"{DATA_DIRECTORY_PATH}/core_scraped/area_code_to_area.json\"\n",
    "with open(area_code_to_area_path) as fd:\n",
    "     area_code_to_area = json.load(fd)\n",
    "     print(f\"E.g. Maps 1100 to {area_code_to_area[\"1100\"]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "def get_geocode(area_code):\n",
    "    # area_code -> (latitude, longitude)\n",
    "    try:\n",
    "        return tuple(jp.citycode2geodetic(area_code)) \n",
    "    except:\n",
    "        print(f\"Could not find geocode for {area_code}\")\n",
    "        return (0, 0)\n",
    "\n",
    "def get_euclidian_distance(geocode1, geocode2):\n",
    "    # lat1, lon1, lat2, lon2 -> distance\n",
    "    lat1, lon1 = geocode1\n",
    "    lat2, lon2 = geocode2\n",
    "    return ((lat1 - lat2)**2 + (lon1 - lon2)**2)**0.5\n",
    "\n",
    "def find_neighbours(area_code, area_to_geocode, n):\n",
    "    geocode = area_to_geocode[area_code]\n",
    "    area_to_distances = { area : get_euclidian_distance(geocode, area_geocode) for area, area_geocode in area_to_geocode.items() if area != area_code }\n",
    "    return sorted(area_to_distances, key=area_to_distances.get)[:n]\n",
    "\n",
    "def find_neighbours_with_distance(area_code, area_to_geocode, n):\n",
    "    geocode = area_to_geocode[area_code]\n",
    "    area_to_distances = { area : get_euclidian_distance(geocode, area_geocode) for area, area_geocode in area_to_geocode.items() if area != area_code }\n",
    "    closest = sorted(area_to_distances, key=area_to_distances.get)[:n]\n",
    "    return { area : area_to_distances[area] for area in closest }\n",
    "\n",
    "# get_euclidian_distance(geocode(13101), geocode(13102))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find geocode for 13362\n",
      "Could not find geocode for 43506\n"
     ]
    }
   ],
   "source": [
    "# Smoothing parameters\n",
    "\n",
    "n_neighbors = 5\n",
    "\n",
    "all_area_codes = list(area_code_to_area.keys())\n",
    "area_to_geocode = {area_code: get_geocode(area_code) for area_code in all_area_codes}\n",
    "area_to_neighbours = {area_code: find_neighbours(area_code, area_to_geocode, 5) for area_code in all_area_codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'13103': 0.00832056392317546,\n",
       " '13102': 0.032463657480348386,\n",
       " '13104': 0.034864796987784656,\n",
       " '13113': 0.04489803650493661,\n",
       " '13105': 0.05288099209545874}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Longitudes and Latitudes\n",
    "# For Area, get 5 closest neighbors\n",
    "\n",
    "# area_to_neighbours\n",
    "find_neighbours_with_distance(\"13101\", area_to_geocode, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for each area_code:\n",
    "    for each year:\n",
    "        get n neighbours\n",
    "\n",
    "        data[area_code][year] = value\n",
    "\n",
    "        # BASIC KERNEL\n",
    "        # Can do spatial smoothing for each year, then temporal smoothing for the rest\n",
    "        # or\n",
    "        # Can do temporal smoothing for each year, then spatial smoothing for the rest\n",
    "\n",
    "        # Spatial Smoothing\n",
    "        0.1 for each neighbour\n",
    "        0.5 for main area\n",
    "\n",
    "        # Temporal Smoothing\n",
    "        0.1 (-2)\n",
    "        0.2 (-1)\n",
    "        0.5 (0)\n",
    "        0.2 (-1)\n",
    "        0.1 (-2)\n",
    "\n",
    "        \n",
    "        '''  area_code, n1, n2, n3\n",
    "        T-2: \n",
    "        T-1:\n",
    "        T0:\n",
    "        T1:\n",
    "        T2:\n",
    "        '''\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "kennedy_town = 20 -> 30\n",
    "SYP = 10 -> 15\n",
    "\n",
    "kennedy_town_smooth_2 = .75 * 20 + .25 * 10 = 17.5\n",
    "kennedy_town_smooth_2 = .75 * 30 + .25 * 15 = 26.25\n",
    "\n",
    "kennedy_return_smooth = .75 * 0.5 + .25 * 0.5 = 0.5\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_type = \"building\"\n",
    "\n",
    "metrics = {\n",
    "    \"weighted_mean\": \"unit_price_wmean\",\n",
    "    \"weighted_median\": \"unit_price_wmedian\",\n",
    "    \"mean\": \"unit_price_mean\",\n",
    "    \"median\": \"unit_price_median\",\n",
    "}\n",
    "\n",
    "dataset_paths = {\n",
    "    \"main\": get_derived_csv_path(asset_type),\n",
    "    \"lpa\": get_derived_lpa_path(),\n",
    "    \"plps\": get_derived_plps_path()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "granularity_columns = [\"area\", \"area_code\"]\n",
    "group_by_columns = granularity_columns + [\"year\"]\n",
    "display_columns = [\"unit_price\", \"total_traded_area\", \"count\"]\n",
    "\n",
    "metric = metrics[\"weighted_median\"]\n",
    "metric_pct_chg = metric + \"_pct_chg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_df_path = dataset_paths[\"main\"]\n",
    "df = pd.read_csv(core_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years(area_df, year, y_backward, y_forward):\n",
    "    years = [year - i for i in range(1, y_backward)] + [\n",
    "        year + i for i in range(1, y_forward)\n",
    "    ]\n",
    "\n",
    "    return [year for year in years if year in area_df[\"year\"].unique()]\n",
    "\n",
    "\n",
    "def get_price(df, area_code, year, metric):\n",
    "    return df[(df[\"area_code\"] == area_code) & (df[\"year\"] == year)][metric].values[0]\n",
    "\n",
    "\n",
    "def scale_distance_to_weight(distance):\n",
    "    return 1 / distance\n",
    "\n",
    "\n",
    "def scale_year_to_weight(year_diff):\n",
    "    return 1 / year_diff\n",
    "\n",
    "\n",
    "def sum_to_one(weights, scale=1):\n",
    "    return [weight / sum(weights) for weight in weights] * scale\n",
    "\n",
    "\n",
    "# Should we smooth on future?\n",
    "\n",
    "\n",
    "def smooth(\n",
    "    df,\n",
    "    year,\n",
    "    area_code,\n",
    "    metric,\n",
    "    n_neighbors=5,\n",
    "    n_years_forward=1,\n",
    "    n_years_backward=1,\n",
    "    area_smoothing_factor=0.5,\n",
    "    year_smoothing_factor=0.5,\n",
    "    distance_scaler=scale_distance_to_weight,\n",
    "    year_scaler=scale_year_to_weight,\n",
    "):\n",
    "    # neighbour weights\n",
    "    neighbours = find_neighbours(area_code, area_to_geocode, n_neighbors)\n",
    "    neighbour_prices = [\n",
    "        get_price(df, neighbour, year, metric) for neighbour in neighbours\n",
    "    ]\n",
    "\n",
    "    distances = [\n",
    "        get_euclidian_distance(area_to_geocode[area_code], area_to_geocode[neighbour])\n",
    "        for neighbour in neighbours\n",
    "    ]\n",
    "    distance_weights = [distance_scaler(distance) for distance in distances]\n",
    "    distance_weights_scaled = sum_to_one(\n",
    "        distance_weights, scale=1 - area_smoothing_factor\n",
    "    )\n",
    "\n",
    "    neighbour_weights = zip(distance_weights_scaled, neighbour_prices)\n",
    "\n",
    "    \"\"\"\n",
    "    [\n",
    "        (weight1, price1),\n",
    "        (weight2, price2),\n",
    "    ]\n",
    "\n",
    "    [\n",
    "        (area_smoothing_factor, og_price)\n",
    "    ]\n",
    "    \"\"\"\n",
    "\n",
    "    # year weights\n",
    "    years = get_years(\n",
    "        df[df[\"area_code\"] == area_code], year, n_years_backward, n_years_forward\n",
    "    )\n",
    "\n",
    "    year_prices = [get_price(df, area_code, year, metric) for year in years]\n",
    "\n",
    "    year_diffs = [abs(year - year_) for year_ in years]\n",
    "    year_diff_weights = [year_scaler(year_diff) for year_diff in year_diffs]\n",
    "    year_diff_weights_scaled = sum_to_one(\n",
    "        year_diff_weights, scale=1 - year_smoothing_factor\n",
    "    )\n",
    "\n",
    "    year_weights = zip(year_diff_weights, year_prices)\n",
    "\n",
    "    og_price = get_price(df, area_code, year, metric)\n",
    "\n",
    "    area_weights = [(area_smoothing_factor, og_price)] + neighbour_weights\n",
    "    area_smoothed_price = np.average(\n",
    "        [v for (_, v) in area_weights], weights=[k for (k, _) in area_weights]\n",
    "    )\n",
    "\n",
    "    # smoothing\n",
    "\n",
    "    area_year_smoothed_price = year_smoothing_factor * area_smoothed_price + (\n",
    "        1 - year_smoothing_factor\n",
    "    ) * sum([weight * price for weight, price in year_weights]) / sum(\n",
    "        [weight for weight, price in year_weights]\n",
    "    )\n",
    "\n",
    "    year_weights_final = [\n",
    "        (year_smoothing_factor, area_year_smoothed_price)\n",
    "    ] + year_weights\n",
    "    area_year_smoothed_price = np.average(\n",
    "        [v for (_, v) in year_weights_final],\n",
    "        weights=[k for (k, _) in year_weights_final],\n",
    "    )\n",
    "\n",
    "    return area_year_smoothed_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4499999999999997"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [3.5, 1, 2]\n",
    "weights = [0.5, 0.3, 0.2]\n",
    "\n",
    "smoothed_price = np.average(values, weights=weights)\n",
    "smoothed_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f\"{metric}_smoothed\"] = df.apply(lambda row: smooth(df, row[\"year\"], row[\"area_code\"], metric), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _ArrayFunctionDispatcher in module numpy:\n",
      "\n",
      "average(a, axis=None, weights=None, returned=False, *, keepdims=<no value>)\n",
      "    Compute the weighted average along the specified axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing data to be averaged. If `a` is not an array, a\n",
      "        conversion is attempted.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which to average `a`.  The default,\n",
      "        axis=None, will average over all of the elements of the input array.\n",
      "        If axis is negative it counts from the last to the first axis.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If axis is a tuple of ints, averaging is performed on all of the axes\n",
      "        specified in the tuple instead of a single axis or all the axes as\n",
      "        before.\n",
      "    weights : array_like, optional\n",
      "        An array of weights associated with the values in `a`. Each value in\n",
      "        `a` contributes to the average according to its associated weight.\n",
      "        The weights array can either be 1-D (in which case its length must be\n",
      "        the size of `a` along the given axis) or of the same shape as `a`.\n",
      "        If `weights=None`, then all data in `a` are assumed to have a\n",
      "        weight equal to one.  The 1-D calculation is::\n",
      "\n",
      "            avg = sum(a * weights) / sum(weights)\n",
      "\n",
      "        The only constraint on `weights` is that `sum(weights)` must not be 0.\n",
      "    returned : bool, optional\n",
      "        Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)\n",
      "        is returned, otherwise only the average is returned.\n",
      "        If `weights=None`, `sum_of_weights` is equivalent to the number of\n",
      "        elements over which the average is taken.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the original `a`.\n",
      "        *Note:* `keepdims` will not work with instances of `numpy.matrix`\n",
      "        or other classes whose methods do not support `keepdims`.\n",
      "\n",
      "        .. versionadded:: 1.23.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    retval, [sum_of_weights] : array_type or double\n",
      "        Return the average along the specified axis. When `returned` is `True`,\n",
      "        return a tuple with the average as the first element and the sum\n",
      "        of the weights as the second element. `sum_of_weights` is of the\n",
      "        same type as `retval`. The result dtype follows a genereal pattern.\n",
      "        If `weights` is None, the result dtype will be that of `a` , or ``float64``\n",
      "        if `a` is integral. Otherwise, if `weights` is not None and `a` is non-\n",
      "        integral, the result type will be the type of lowest precision capable of\n",
      "        representing values of both `a` and `weights`. If `a` happens to be\n",
      "        integral, the previous rules still applies but the result dtype will\n",
      "        at least be ``float64``.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ZeroDivisionError\n",
      "        When all weights along axis are zero. See `numpy.ma.average` for a\n",
      "        version robust to this type of error.\n",
      "    TypeError\n",
      "        When the length of 1D `weights` is not the same as the shape of `a`\n",
      "        along axis.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    mean\n",
      "\n",
      "    ma.average : average for masked arrays -- useful if your data contains\n",
      "                 \"missing\" values\n",
      "    numpy.result_type : Returns the type that results from applying the\n",
      "                        numpy type promotion rules to the arguments.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> data = np.arange(1, 5)\n",
      "    >>> data\n",
      "    array([1, 2, 3, 4])\n",
      "    >>> np.average(data)\n",
      "    2.5\n",
      "    >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))\n",
      "    4.0\n",
      "\n",
      "    >>> data = np.arange(6).reshape((3, 2))\n",
      "    >>> data\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5]])\n",
      "    >>> np.average(data, axis=1, weights=[1./4, 3./4])\n",
      "    array([0.75, 2.75, 4.75])\n",
      "    >>> np.average(data, weights=[1./4, 3./4])\n",
      "    Traceback (most recent call last):\n",
      "        ...\n",
      "    TypeError: Axis must be specified when shapes of a and weights differ.\n",
      "\n",
      "    >>> a = np.ones(5, dtype=np.float128)\n",
      "    >>> w = np.ones(5, dtype=np.complex64)\n",
      "    >>> avg = np.average(a, weights=w)\n",
      "    >>> print(avg.dtype)\n",
      "    complex256\n",
      "\n",
      "    With ``keepdims=True``, the following result has shape (3, 1).\n",
      "\n",
      "    >>> np.average(data, axis=1, keepdims=True)\n",
      "    array([[0.5],\n",
      "           [2.5],\n",
      "           [4.5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2013\n",
    "[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
