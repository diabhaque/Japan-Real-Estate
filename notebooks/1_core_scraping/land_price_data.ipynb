{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "from jre_utils.datapath import DATA_DIRECTORY_PATH\n",
    "\n",
    "# selenium 4\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not rerun accidentally\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlit_url(mod, year, page=0):\n",
    "    return f\"https://www.land.mlit.go.jp/landPrice/SearchServlet?nccharset=953DFDC5&MOD={mod}&TDK=&SKC=&CHI=&YFR={year}&YTO={year}&YOU=0%2C3%2C5%2C7%2C9&PFR=&PTO=&PG={page}&LATEST_YEAR=\"\n",
    "\n",
    "\n",
    "def get_lpa_url(year, page=0):\n",
    "    return get_mlit_url(0, year, page)\n",
    "\n",
    "\n",
    "def get_plps_url(year, page=0):\n",
    "    return get_mlit_url(1, year, page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plps_year_to_page_count_path = f\"{DATA_DIRECTORY_PATH}/core_scraped/plps_year_to_page_count.json\"\n",
    "lpa_year_to_page_count_path = f\"{DATA_DIRECTORY_PATH}/core_scraped/lpa_year_to_page_count.json\"\n",
    "\n",
    "with open(plps_year_to_page_count_path) as fd:\n",
    "     plps_year_to_page_count = json.load(fd)\n",
    "    #  pprint(plps_year_to_page_count)\n",
    "\n",
    "with open(lpa_year_to_page_count_path) as fd:\n",
    "     lpa_year_to_page_count = json.load(fd)\n",
    "    #  pprint(lpa_year_to_page_count)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30732, 55977)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_plps_pages = sum(plps_year_to_page_count.values())\n",
    "num_lpa_pages = sum(lpa_year_to_page_count.values())\n",
    "num_plps_pages, num_lpa_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "thought = \"Also, I’m about to make 80,000 requests to a server. By my estimate, it’ll take 20 or so hours. This seems borderline illegal haha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datalist_element_to_dict(datalist_element):\n",
    "    \"\"\"\n",
    "    This works because each datalist element is similar in structure to the following:\n",
    "    <div class=\"datalist\">\n",
    "        <div class=\"datalistline\">\n",
    "            <div class=\"datalistkey\">Key</div>\n",
    "            <div class=\"datalistvalue\">Value</div>\n",
    "            <div class=\"datalistkey\">Key</div>\n",
    "            <div class=\"datalistvalue2\">Value</div>\n",
    "        </div>\n",
    "        ...\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    key_vals = []\n",
    "    html = datalist_element.get_attribute('innerHTML')\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    datalist_lines = soup.find_all(class_='datalistline')\n",
    "\n",
    "    for datalist_line in datalist_lines:\n",
    "        children = [\" \".join(div.stripped_strings) for div in datalist_line.find_all(\"div\", recursive=False)]\n",
    "        key_vals += [(children[i], children[i + 1]) for i in range(0, len(children), 2)]\n",
    "\n",
    "    return dict(key_vals)\n",
    "\n",
    "def get_land_price_data(driver, url):\n",
    "    driver.get(url)\n",
    "    datalist_elements = driver.find_elements(By.CLASS_NAME, 'datalist')\n",
    "    elements = [datalist_element_to_dict(datalist_element) for datalist_element in datalist_elements]\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1047 [02:58<?, ?it/s]\n",
      "100%|██████████| 1047/1047 [15:55<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_year = \"X\" # 2023\n",
    "page_count = plps_year_to_page_count[test_year]\n",
    "pbar = tqdm(total=page_count)\n",
    "\n",
    "all_elements = []\n",
    "\n",
    "for page in range(1, page_count + 1):\n",
    "    url = get_plps_url(2023, page)\n",
    "    # all_elements += get_land_price_data(driver, url)\n",
    "    pbar.update()\n",
    "\n",
    "pbar.close()\n",
    "# pd.DataFrame.from_records(all_elements).to_csv(f\"{DATA_DIRECTORY_PATH}/core_scraped/plps/{test_year}.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27426 entries, 0 to 27425\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   基準地番号             27426 non-null  object \n",
      " 1   調査基準日             27426 non-null  object \n",
      " 2   所在及び地番            27426 non-null  object \n",
      " 3   住居表示              7730 non-null   object \n",
      " 4   価格(円/m²)          27426 non-null  object \n",
      " 5   交通施設、距離           27426 non-null  object \n",
      " 6   地積(m²)            27426 non-null  object \n",
      " 7   形状（間口：奥行き）        27192 non-null  object \n",
      " 8   利用区分、構造           27426 non-null  object \n",
      " 9   利用現況              0 non-null      float64\n",
      " 10  給排水等状況            27426 non-null  object \n",
      " 11  周辺の土地の利用現況        0 non-null      float64\n",
      " 12  前面道路の状況           27339 non-null  object \n",
      " 13  その他の接面道路          3320 non-null   object \n",
      " 14  用途区分、高度地区、防火・準防火  19083 non-null  object \n",
      " 15  建ぺい率（%）、容積率（%）    27426 non-null  object \n",
      " 16  都市計画区域区分          27426 non-null  object \n",
      " 17  森林法、公園法、 自然環境等    0 non-null      float64\n",
      "dtypes: float64(3), object(15)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "pd.read_csv(f\"{DATA_DIRECTORY_PATH}/core_scraped/plps/{1997}.csv\").info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plps_completed_years = [\"2023\"]\n",
    "lpa_completed_years = [\"1971\", \"1972\", \"1973\", \"1974\", \"1975\", \"1976\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30732 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29685/30732 [9:17:16<19:39,  1.13s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Scraping Prefectural Land Price Survey (PLPS) data\n",
    "pbar = tqdm(total=num_plps_pages)\n",
    "\n",
    "for year, page_count in plps_year_to_page_count.items():\n",
    "    if year in plps_completed_years:\n",
    "        continue\n",
    "\n",
    "    all_elements = []\n",
    "    for page in range(1, page_count + 1):\n",
    "        url = get_plps_url(year, page)\n",
    "        # all_elements += get_land_price_data(driver, url)\n",
    "        pbar.update()\n",
    "\n",
    "    # pd.DataFrame.from_records(all_elements).to_csv(f\"{DATA_DIRECTORY_PATH}/core_scraping/plps/{year}.csv\", index=False)\n",
    "\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2549/55977 [1:21:19<28:24:35,  1.91s/it] \n",
      " 96%|█████████▌| 53512/55977 [15:41:47<43:22,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "# Scraping Land Price Announcement (LPA) data\n",
    "pbar = tqdm(total=num_lpa_pages)\n",
    "\n",
    "for year, page_count in lpa_year_to_page_count.items():\n",
    "    if year in lpa_completed_years:\n",
    "        continue\n",
    "\n",
    "    all_elements = []\n",
    "    for page in range(1, page_count + 1):\n",
    "        url = get_lpa_url(year, page)\n",
    "        # all_elements += get_land_price_data(driver, url)\n",
    "        pbar.update()\n",
    "\n",
    "    # pd.DataFrame.from_records(all_elements).to_csv(f\"{DATA_DIRECTORY_PATH}/core_scraped/lpa/{year}.csv\", index=False)\n",
    "\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
