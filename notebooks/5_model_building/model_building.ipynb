{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import get_scheduler\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "\n",
    "\n",
    "from jre_utils.datapath import model_ready_data_paths, model_output_data_paths\n",
    "from jre_utils.data import JapanRETimeSeriesDataset, PadAndMask, ToNumpy, ToTensor\n",
    "from jre_utils.models import TimeSeriesTransformerModel\n",
    "from jre_utils.metrics import MSELossWeighted\n",
    "from jre_utils.engine import (\n",
    "    evaluate,\n",
    "    train,\n",
    "    evaluate_weighted,\n",
    "    train_weighted,\n",
    "    EarlyStopper,\n",
    ")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"weighted_mean\": \"unit_price_wmean\",\n",
    "    \"weighted_median\": \"unit_price_wmedian\",\n",
    "    \"mean\": \"unit_price_mean\",\n",
    "    \"median\": \"unit_price_median\",\n",
    "    \"weighted_mean_smoothed\": \"unit_price_wmean_smoothed\",\n",
    "    \"weighted_median_smoothed\": \"unit_price_wmedian_smoothed\",\n",
    "    \"mean_smoothed\": \"unit_price_mean_smoothed\",\n",
    "    \"median_smoothed\": \"unit_price_median_smoothed\",\n",
    "}\n",
    "\n",
    "granularity_columns = [\"area\", \"area_code\"]\n",
    "group_by_columns = granularity_columns + [\"year\"]\n",
    "display_columns = [\"unit_price\", \"total_traded_area\", \"count\"]\n",
    "\n",
    "metric_key_unsmoothed = \"median\"\n",
    "metric_unsmoothed = metrics[metric_key_unsmoothed]\n",
    "\n",
    "metric_key = f\"{metric_key_unsmoothed}_smoothed\"\n",
    "metric = metrics[metric_key]\n",
    "\n",
    "metric_pct_chg = metric + \"_pct_chg\"\n",
    "normalized_metric_pct_chg = metric_pct_chg + \"_normalized_yearly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2006\n",
    "eval_start_year = 2020 # eval_years = [2020, 2021, 2022]\n",
    "eval_end_year = 2022\n",
    "\n",
    "dataset_key = \"transactions\"\n",
    "years_ahead = 2\n",
    "dataset_name = f\"sequence_{dataset_key}_{metric_key}_{years_ahead}\"\n",
    "output_dataset_name = f\"{dataset_name}_{eval_start_year}\"\n",
    "model_ready_data_path = model_ready_data_paths[dataset_name]\n",
    "model_output_data_path = model_output_data_paths[output_dataset_name]\n",
    "\n",
    "df = pd.read_csv(model_ready_data_path)\n",
    "df = df[df[\"year\"] <= eval_end_year]\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = df.sort_values(by=[\"year\"]).reset_index(drop=True)\n",
    "\n",
    "df[\"count_scaled\"] = df[\"count\"].apply(lambda x: 1 + np.log10(x))\n",
    "\n",
    "train_df = df[(df[\"year\"] >= start_year) & (df[\"year\"] < eval_start_year)].reset_index(drop=True)\n",
    "eval_df = df[df[\"year\"] >= eval_start_year].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>unit_price_median_smoothed</th>\n",
       "      <th>unit_price_median_smoothed_pct_chg</th>\n",
       "      <th>unit_price_median_smoothed_pct_chg_normalized_yearly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>2.204983e+06</td>\n",
       "      <td>0.227171</td>\n",
       "      <td>2.619291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2008</td>\n",
       "      <td>2.197454e+06</td>\n",
       "      <td>0.139858</td>\n",
       "      <td>1.066988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>2009</td>\n",
       "      <td>2.069647e+06</td>\n",
       "      <td>-0.061378</td>\n",
       "      <td>-0.060949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.825045e+06</td>\n",
       "      <td>-0.169473</td>\n",
       "      <td>-0.456003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>2011</td>\n",
       "      <td>1.620211e+06</td>\n",
       "      <td>-0.217156</td>\n",
       "      <td>-0.780465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>2012</td>\n",
       "      <td>1.684720e+06</td>\n",
       "      <td>-0.076888</td>\n",
       "      <td>-0.332538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>2013</td>\n",
       "      <td>1.947510e+06</td>\n",
       "      <td>0.202010</td>\n",
       "      <td>1.113350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7155</th>\n",
       "      <td>2014</td>\n",
       "      <td>2.130575e+06</td>\n",
       "      <td>0.264646</td>\n",
       "      <td>1.446387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8667</th>\n",
       "      <td>2015</td>\n",
       "      <td>2.257352e+06</td>\n",
       "      <td>0.159097</td>\n",
       "      <td>0.843063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10020</th>\n",
       "      <td>2016</td>\n",
       "      <td>2.645833e+06</td>\n",
       "      <td>0.241840</td>\n",
       "      <td>1.197871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10886</th>\n",
       "      <td>2017</td>\n",
       "      <td>2.855318e+06</td>\n",
       "      <td>0.264897</td>\n",
       "      <td>1.325756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>2018</td>\n",
       "      <td>3.061267e+06</td>\n",
       "      <td>0.157014</td>\n",
       "      <td>0.792784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14219</th>\n",
       "      <td>2019</td>\n",
       "      <td>3.398634e+06</td>\n",
       "      <td>0.190282</td>\n",
       "      <td>0.999511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  unit_price_median_smoothed  unit_price_median_smoothed_pct_chg  \\\n",
       "2      2007                2.204983e+06                            0.227171   \n",
       "28     2008                2.197454e+06                            0.139858   \n",
       "766    2009                2.069647e+06                           -0.061378   \n",
       "2029   2010                1.825045e+06                           -0.169473   \n",
       "2358   2011                1.620211e+06                           -0.217156   \n",
       "5087   2012                1.684720e+06                           -0.076888   \n",
       "5602   2013                1.947510e+06                            0.202010   \n",
       "7155   2014                2.130575e+06                            0.264646   \n",
       "8667   2015                2.257352e+06                            0.159097   \n",
       "10020  2016                2.645833e+06                            0.241840   \n",
       "10886  2017                2.855318e+06                            0.264897   \n",
       "12596  2018                3.061267e+06                            0.157014   \n",
       "14219  2019                3.398634e+06                            0.190282   \n",
       "\n",
       "       unit_price_median_smoothed_pct_chg_normalized_yearly  \n",
       "2                                               2.619291     \n",
       "28                                              1.066988     \n",
       "766                                            -0.060949     \n",
       "2029                                           -0.456003     \n",
       "2358                                           -0.780465     \n",
       "5087                                           -0.332538     \n",
       "5602                                            1.113350     \n",
       "7155                                            1.446387     \n",
       "8667                                            0.843063     \n",
       "10020                                           1.197871     \n",
       "10886                                           1.325756     \n",
       "12596                                           0.792784     \n",
       "14219                                           0.999511     "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"area_code\"] == 13101][[\"year\", metric, metric_pct_chg, normalized_metric_pct_chg]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>unit_price_median_smoothed</th>\n",
       "      <th>unit_price_median_smoothed_pct_chg</th>\n",
       "      <th>unit_price_median_smoothed_pct_chg_normalized_yearly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>2020</td>\n",
       "      <td>3.849920e+06</td>\n",
       "      <td>0.257623</td>\n",
       "      <td>1.115681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2021</td>\n",
       "      <td>4.164547e+06</td>\n",
       "      <td>0.225359</td>\n",
       "      <td>0.829393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>2022</td>\n",
       "      <td>4.462737e+06</td>\n",
       "      <td>0.159177</td>\n",
       "      <td>0.495757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  unit_price_median_smoothed  unit_price_median_smoothed_pct_chg  \\\n",
       "1147  2020                3.849920e+06                            0.257623   \n",
       "2191  2021                4.164547e+06                            0.225359   \n",
       "3158  2022                4.462737e+06                            0.159177   \n",
       "\n",
       "      unit_price_median_smoothed_pct_chg_normalized_yearly  \n",
       "1147                                           1.115681     \n",
       "2191                                           0.829393     \n",
       "3158                                           0.495757     "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df[eval_df[\"area_code\"] == 13101][[\"year\", metric, metric_pct_chg, normalized_metric_pct_chg]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0.4957566755770115\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_price_median_smoothed_pct_chg</th>\n",
       "      <th>unit_price_median_smoothed</th>\n",
       "      <th>unit_price_median</th>\n",
       "      <th>year</th>\n",
       "      <th>years_since_crisis</th>\n",
       "      <th>count</th>\n",
       "      <th>total_traded_area</th>\n",
       "      <th>population</th>\n",
       "      <th>taxpayer_count</th>\n",
       "      <th>taxable_income</th>\n",
       "      <th>taxable_income_per_taxpayer</th>\n",
       "      <th>taxable_income_growth</th>\n",
       "      <th>taxable_income_per_taxpayer_growth</th>\n",
       "      <th>total_tax</th>\n",
       "      <th>total_tax_growth</th>\n",
       "      <th>new_dwellings</th>\n",
       "      <th>existing_dwellings</th>\n",
       "      <th>net_migration_ratio</th>\n",
       "      <th>new_dwellings_ratio</th>\n",
       "      <th>migrations_is_available</th>\n",
       "      <th>taxable_income_is_available</th>\n",
       "      <th>dwellings_is_available</th>\n",
       "      <th>total_tax_is_available</th>\n",
       "      <th>area_code</th>\n",
       "      <th>area</th>\n",
       "      <th>new_dwellings_ratio_normalized_yearly</th>\n",
       "      <th>log_new_dwellings_ratio</th>\n",
       "      <th>log_new_dwellings_ratio_normalized_yearly</th>\n",
       "      <th>unit_price_median_smoothed_log</th>\n",
       "      <th>unit_price_median_smoothed_log_normalized_yearly</th>\n",
       "      <th>count_log</th>\n",
       "      <th>count_log_normalized_yearly</th>\n",
       "      <th>total_traded_area_log</th>\n",
       "      <th>total_traded_area_log_normalized_yearly</th>\n",
       "      <th>population_log</th>\n",
       "      <th>population_log_normalized_yearly</th>\n",
       "      <th>taxpayer_count_log</th>\n",
       "      <th>taxpayer_count_log_normalized_yearly</th>\n",
       "      <th>taxable_income_log</th>\n",
       "      <th>taxable_income_log_normalized_yearly</th>\n",
       "      <th>taxable_income_per_taxpayer_log</th>\n",
       "      <th>taxable_income_per_taxpayer_log_normalized_yearly</th>\n",
       "      <th>total_tax_log</th>\n",
       "      <th>total_tax_log_normalized_yearly</th>\n",
       "      <th>new_dwellings_log</th>\n",
       "      <th>new_dwellings_log_normalized_yearly</th>\n",
       "      <th>existing_dwellings_log</th>\n",
       "      <th>existing_dwellings_log_normalized_yearly</th>\n",
       "      <th>unit_price_median_smoothed_pct_chg_normalized_yearly</th>\n",
       "      <th>total_tax_growth_normalized_yearly</th>\n",
       "      <th>taxable_income_growth_normalized_yearly</th>\n",
       "      <th>taxable_income_per_taxpayer_growth_normalized_yearly</th>\n",
       "      <th>net_migration_ratio_normalized_yearly</th>\n",
       "      <th>unit_price_median_smoothed_normalized_yearly</th>\n",
       "      <th>count_normalized_yearly</th>\n",
       "      <th>total_traded_area_normalized_yearly</th>\n",
       "      <th>population_normalized_yearly</th>\n",
       "      <th>taxpayer_count_normalized_yearly</th>\n",
       "      <th>taxable_income_normalized_yearly</th>\n",
       "      <th>taxable_income_per_taxpayer_normalized_yearly</th>\n",
       "      <th>new_dwellings_normalized_yearly</th>\n",
       "      <th>existing_dwellings_normalized_yearly</th>\n",
       "      <th>total_tax_normalized_yearly</th>\n",
       "      <th>migrations_is_available_normalized_yearly</th>\n",
       "      <th>taxable_income_is_available_normalized_yearly</th>\n",
       "      <th>dwellings_is_available_normalized_yearly</th>\n",
       "      <th>total_tax_is_available_normalized_yearly</th>\n",
       "      <th>count_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10020</th>\n",
       "      <td>0.241840</td>\n",
       "      <td>2.645833e+06</td>\n",
       "      <td>2.645833e+06</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>58.0</td>\n",
       "      <td>9205.0</td>\n",
       "      <td>60870.0</td>\n",
       "      <td>34324.0</td>\n",
       "      <td>314359478.0</td>\n",
       "      <td>9158.591015</td>\n",
       "      <td>0.123044</td>\n",
       "      <td>0.079495</td>\n",
       "      <td>18441614.0</td>\n",
       "      <td>0.057706</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>38740.0</td>\n",
       "      <td>0.014473</td>\n",
       "      <td>0.039881</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13101</td>\n",
       "      <td>Tokyo-to Chiyoda-ku</td>\n",
       "      <td>3.645084</td>\n",
       "      <td>-0.399231</td>\n",
       "      <td>2.260922</td>\n",
       "      <td>7.422562</td>\n",
       "      <td>3.774222</td>\n",
       "      <td>2.763428</td>\n",
       "      <td>0.523342</td>\n",
       "      <td>4.964024</td>\n",
       "      <td>0.038018</td>\n",
       "      <td>5.784403</td>\n",
       "      <td>0.380994</td>\n",
       "      <td>5.535598</td>\n",
       "      <td>0.579343</td>\n",
       "      <td>9.497427</td>\n",
       "      <td>1.416775</td>\n",
       "      <td>4.961829</td>\n",
       "      <td>7.516626</td>\n",
       "      <td>8.265799</td>\n",
       "      <td>1.001951</td>\n",
       "      <td>4.188928</td>\n",
       "      <td>0.953829</td>\n",
       "      <td>5.588160</td>\n",
       "      <td>0.043625</td>\n",
       "      <td>1.197871</td>\n",
       "      <td>1.242587</td>\n",
       "      <td>3.332668</td>\n",
       "      <td>2.801374</td>\n",
       "      <td>2.891238</td>\n",
       "      <td>16.231302</td>\n",
       "      <td>-0.112194</td>\n",
       "      <td>-0.270920</td>\n",
       "      <td>-0.141833</td>\n",
       "      <td>-0.066958</td>\n",
       "      <td>0.498455</td>\n",
       "      <td>10.691254</td>\n",
       "      <td>0.441195</td>\n",
       "      <td>-0.015471</td>\n",
       "      <td>0.120489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06613</td>\n",
       "      <td>0.836356</td>\n",
       "      <td>0.026948</td>\n",
       "      <td>2.763428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10886</th>\n",
       "      <td>0.264897</td>\n",
       "      <td>2.855318e+06</td>\n",
       "      <td>3.937500e+06</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7930.0</td>\n",
       "      <td>61751.0</td>\n",
       "      <td>35326.0</td>\n",
       "      <td>333664476.0</td>\n",
       "      <td>9445.294571</td>\n",
       "      <td>0.061411</td>\n",
       "      <td>0.031304</td>\n",
       "      <td>19084096.0</td>\n",
       "      <td>0.034839</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>40285.0</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>0.035125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13101</td>\n",
       "      <td>Tokyo-to Chiyoda-ku</td>\n",
       "      <td>3.521004</td>\n",
       "      <td>-0.454387</td>\n",
       "      <td>2.187680</td>\n",
       "      <td>7.455655</td>\n",
       "      <td>3.798386</td>\n",
       "      <td>2.681241</td>\n",
       "      <td>0.388403</td>\n",
       "      <td>4.899273</td>\n",
       "      <td>-0.096657</td>\n",
       "      <td>5.790644</td>\n",
       "      <td>0.394623</td>\n",
       "      <td>5.548094</td>\n",
       "      <td>0.593036</td>\n",
       "      <td>9.523310</td>\n",
       "      <td>1.445119</td>\n",
       "      <td>4.975216</td>\n",
       "      <td>7.684541</td>\n",
       "      <td>8.280672</td>\n",
       "      <td>1.018779</td>\n",
       "      <td>4.150756</td>\n",
       "      <td>0.915407</td>\n",
       "      <td>5.605143</td>\n",
       "      <td>0.069870</td>\n",
       "      <td>1.325756</td>\n",
       "      <td>0.600536</td>\n",
       "      <td>1.082507</td>\n",
       "      <td>0.665260</td>\n",
       "      <td>3.529738</td>\n",
       "      <td>16.441401</td>\n",
       "      <td>-0.162684</td>\n",
       "      <td>-0.309082</td>\n",
       "      <td>-0.137364</td>\n",
       "      <td>-0.061498</td>\n",
       "      <td>0.531391</td>\n",
       "      <td>11.023900</td>\n",
       "      <td>0.386022</td>\n",
       "      <td>-0.007160</td>\n",
       "      <td>0.131257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06613</td>\n",
       "      <td>0.836356</td>\n",
       "      <td>0.026948</td>\n",
       "      <td>2.681241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>0.157014</td>\n",
       "      <td>3.061267e+06</td>\n",
       "      <td>3.061189e+06</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8190.0</td>\n",
       "      <td>62833.0</td>\n",
       "      <td>36299.0</td>\n",
       "      <td>362690825.0</td>\n",
       "      <td>9991.758037</td>\n",
       "      <td>0.086993</td>\n",
       "      <td>0.057856</td>\n",
       "      <td>19816187.0</td>\n",
       "      <td>0.038361</td>\n",
       "      <td>978.0</td>\n",
       "      <td>41700.0</td>\n",
       "      <td>0.032212</td>\n",
       "      <td>0.023453</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13101</td>\n",
       "      <td>Tokyo-to Chiyoda-ku</td>\n",
       "      <td>1.962634</td>\n",
       "      <td>-0.629797</td>\n",
       "      <td>1.385822</td>\n",
       "      <td>7.485901</td>\n",
       "      <td>3.808761</td>\n",
       "      <td>2.698970</td>\n",
       "      <td>0.430708</td>\n",
       "      <td>4.913284</td>\n",
       "      <td>-0.034414</td>\n",
       "      <td>5.798188</td>\n",
       "      <td>0.410692</td>\n",
       "      <td>5.559895</td>\n",
       "      <td>0.607849</td>\n",
       "      <td>9.559537</td>\n",
       "      <td>1.490338</td>\n",
       "      <td>4.999642</td>\n",
       "      <td>7.906475</td>\n",
       "      <td>8.297020</td>\n",
       "      <td>1.035597</td>\n",
       "      <td>3.990339</td>\n",
       "      <td>0.622948</td>\n",
       "      <td>5.620136</td>\n",
       "      <td>0.092997</td>\n",
       "      <td>0.792784</td>\n",
       "      <td>0.767911</td>\n",
       "      <td>1.390629</td>\n",
       "      <td>1.050529</td>\n",
       "      <td>6.184275</td>\n",
       "      <td>17.107678</td>\n",
       "      <td>-0.147566</td>\n",
       "      <td>-0.301729</td>\n",
       "      <td>-0.131970</td>\n",
       "      <td>-0.055703</td>\n",
       "      <td>0.583629</td>\n",
       "      <td>11.587289</td>\n",
       "      <td>0.154911</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>0.122456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06613</td>\n",
       "      <td>0.835103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14219</th>\n",
       "      <td>0.190282</td>\n",
       "      <td>3.398634e+06</td>\n",
       "      <td>3.369318e+06</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>8015.0</td>\n",
       "      <td>64857.0</td>\n",
       "      <td>38175.0</td>\n",
       "      <td>412894018.0</td>\n",
       "      <td>10815.822344</td>\n",
       "      <td>0.138419</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>21648748.0</td>\n",
       "      <td>0.092478</td>\n",
       "      <td>787.0</td>\n",
       "      <td>42487.0</td>\n",
       "      <td>0.028108</td>\n",
       "      <td>0.018523</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13101</td>\n",
       "      <td>Tokyo-to Chiyoda-ku</td>\n",
       "      <td>1.609337</td>\n",
       "      <td>-0.732281</td>\n",
       "      <td>1.152682</td>\n",
       "      <td>7.531304</td>\n",
       "      <td>3.852696</td>\n",
       "      <td>2.681241</td>\n",
       "      <td>0.411331</td>\n",
       "      <td>4.903904</td>\n",
       "      <td>-0.052764</td>\n",
       "      <td>5.811957</td>\n",
       "      <td>0.438657</td>\n",
       "      <td>5.581779</td>\n",
       "      <td>0.641640</td>\n",
       "      <td>9.615839</td>\n",
       "      <td>1.569186</td>\n",
       "      <td>5.034060</td>\n",
       "      <td>8.218735</td>\n",
       "      <td>8.335433</td>\n",
       "      <td>1.092918</td>\n",
       "      <td>3.895975</td>\n",
       "      <td>0.506015</td>\n",
       "      <td>5.628256</td>\n",
       "      <td>0.099687</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>2.562201</td>\n",
       "      <td>3.308448</td>\n",
       "      <td>2.268437</td>\n",
       "      <td>5.265364</td>\n",
       "      <td>18.154210</td>\n",
       "      <td>-0.152671</td>\n",
       "      <td>-0.304405</td>\n",
       "      <td>-0.122051</td>\n",
       "      <td>-0.041034</td>\n",
       "      <td>0.687880</td>\n",
       "      <td>12.233268</td>\n",
       "      <td>0.099425</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.152989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06613</td>\n",
       "      <td>0.835103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.681241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15880</th>\n",
       "      <td>0.257623</td>\n",
       "      <td>3.849920e+06</td>\n",
       "      <td>3.787942e+06</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>66680.0</td>\n",
       "      <td>39873.0</td>\n",
       "      <td>400984266.0</td>\n",
       "      <td>10056.536152</td>\n",
       "      <td>-0.028845</td>\n",
       "      <td>-0.070201</td>\n",
       "      <td>20573851.0</td>\n",
       "      <td>-0.049652</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>43646.0</td>\n",
       "      <td>0.014607</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13101</td>\n",
       "      <td>Tokyo-to Chiyoda-ku</td>\n",
       "      <td>3.235951</td>\n",
       "      <td>-0.575861</td>\n",
       "      <td>2.074750</td>\n",
       "      <td>7.585452</td>\n",
       "      <td>3.896217</td>\n",
       "      <td>2.477121</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>4.550228</td>\n",
       "      <td>-0.789141</td>\n",
       "      <td>5.823996</td>\n",
       "      <td>0.463495</td>\n",
       "      <td>5.600679</td>\n",
       "      <td>0.672562</td>\n",
       "      <td>9.603127</td>\n",
       "      <td>1.539504</td>\n",
       "      <td>5.002448</td>\n",
       "      <td>7.945012</td>\n",
       "      <td>8.313316</td>\n",
       "      <td>1.061534</td>\n",
       "      <td>4.064083</td>\n",
       "      <td>0.882594</td>\n",
       "      <td>5.639944</td>\n",
       "      <td>0.116210</td>\n",
       "      <td>1.115681</td>\n",
       "      <td>-1.299834</td>\n",
       "      <td>-1.115713</td>\n",
       "      <td>-2.877245</td>\n",
       "      <td>3.201692</td>\n",
       "      <td>19.194516</td>\n",
       "      <td>-0.267504</td>\n",
       "      <td>-0.439973</td>\n",
       "      <td>-0.113077</td>\n",
       "      <td>-0.027040</td>\n",
       "      <td>0.645654</td>\n",
       "      <td>11.510370</td>\n",
       "      <td>0.348051</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.134451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06613</td>\n",
       "      <td>0.835103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.477121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit_price_median_smoothed_pct_chg  unit_price_median_smoothed  \\\n",
       "10020                            0.241840                2.645833e+06   \n",
       "10886                            0.264897                2.855318e+06   \n",
       "12596                            0.157014                3.061267e+06   \n",
       "14219                            0.190282                3.398634e+06   \n",
       "15880                            0.257623                3.849920e+06   \n",
       "\n",
       "       unit_price_median  year  years_since_crisis  count  total_traded_area  \\\n",
       "10020       2.645833e+06  2016                   8   58.0             9205.0   \n",
       "10886       3.937500e+06  2017                   9   48.0             7930.0   \n",
       "12596       3.061189e+06  2018                  10   50.0             8190.0   \n",
       "14219       3.369318e+06  2019                   0   48.0             8015.0   \n",
       "15880       3.787942e+06  2020                   1   30.0             3550.0   \n",
       "\n",
       "       population  taxpayer_count  taxable_income  \\\n",
       "10020     60870.0         34324.0     314359478.0   \n",
       "10886     61751.0         35326.0     333664476.0   \n",
       "12596     62833.0         36299.0     362690825.0   \n",
       "14219     64857.0         38175.0     412894018.0   \n",
       "15880     66680.0         39873.0     400984266.0   \n",
       "\n",
       "       taxable_income_per_taxpayer  taxable_income_growth  \\\n",
       "10020                  9158.591015               0.123044   \n",
       "10886                  9445.294571               0.061411   \n",
       "12596                  9991.758037               0.086993   \n",
       "14219                 10815.822344               0.138419   \n",
       "15880                 10056.536152              -0.028845   \n",
       "\n",
       "       taxable_income_per_taxpayer_growth   total_tax  total_tax_growth  \\\n",
       "10020                            0.079495  18441614.0          0.057706   \n",
       "10886                            0.031304  19084096.0          0.034839   \n",
       "12596                            0.057856  19816187.0          0.038361   \n",
       "14219                            0.082474  21648748.0          0.092478   \n",
       "15880                           -0.070201  20573851.0         -0.049652   \n",
       "\n",
       "       new_dwellings  existing_dwellings  net_migration_ratio  \\\n",
       "10020         1545.0             38740.0             0.014473   \n",
       "10886         1415.0             40285.0             0.017522   \n",
       "12596          978.0             41700.0             0.032212   \n",
       "14219          787.0             42487.0             0.028108   \n",
       "15880         1159.0             43646.0             0.014607   \n",
       "\n",
       "       new_dwellings_ratio  migrations_is_available  \\\n",
       "10020             0.039881                        1   \n",
       "10886             0.035125                        1   \n",
       "12596             0.023453                        1   \n",
       "14219             0.018523                        1   \n",
       "15880             0.026555                        1   \n",
       "\n",
       "       taxable_income_is_available  dwellings_is_available  \\\n",
       "10020                            1                       1   \n",
       "10886                            1                       1   \n",
       "12596                            1                       1   \n",
       "14219                            1                       1   \n",
       "15880                            1                       1   \n",
       "\n",
       "       total_tax_is_available  area_code                 area  \\\n",
       "10020                       1      13101  Tokyo-to Chiyoda-ku   \n",
       "10886                       1      13101  Tokyo-to Chiyoda-ku   \n",
       "12596                       1      13101  Tokyo-to Chiyoda-ku   \n",
       "14219                       1      13101  Tokyo-to Chiyoda-ku   \n",
       "15880                       1      13101  Tokyo-to Chiyoda-ku   \n",
       "\n",
       "       new_dwellings_ratio_normalized_yearly  log_new_dwellings_ratio  \\\n",
       "10020                               3.645084                -0.399231   \n",
       "10886                               3.521004                -0.454387   \n",
       "12596                               1.962634                -0.629797   \n",
       "14219                               1.609337                -0.732281   \n",
       "15880                               3.235951                -0.575861   \n",
       "\n",
       "       log_new_dwellings_ratio_normalized_yearly  \\\n",
       "10020                                   2.260922   \n",
       "10886                                   2.187680   \n",
       "12596                                   1.385822   \n",
       "14219                                   1.152682   \n",
       "15880                                   2.074750   \n",
       "\n",
       "       unit_price_median_smoothed_log  \\\n",
       "10020                        7.422562   \n",
       "10886                        7.455655   \n",
       "12596                        7.485901   \n",
       "14219                        7.531304   \n",
       "15880                        7.585452   \n",
       "\n",
       "       unit_price_median_smoothed_log_normalized_yearly  count_log  \\\n",
       "10020                                          3.774222   2.763428   \n",
       "10886                                          3.798386   2.681241   \n",
       "12596                                          3.808761   2.698970   \n",
       "14219                                          3.852696   2.681241   \n",
       "15880                                          3.896217   2.477121   \n",
       "\n",
       "       count_log_normalized_yearly  total_traded_area_log  \\\n",
       "10020                     0.523342               4.964024   \n",
       "10886                     0.388403               4.899273   \n",
       "12596                     0.430708               4.913284   \n",
       "14219                     0.411331               4.903904   \n",
       "15880                     0.000391               4.550228   \n",
       "\n",
       "       total_traded_area_log_normalized_yearly  population_log  \\\n",
       "10020                                 0.038018        5.784403   \n",
       "10886                                -0.096657        5.790644   \n",
       "12596                                -0.034414        5.798188   \n",
       "14219                                -0.052764        5.811957   \n",
       "15880                                -0.789141        5.823996   \n",
       "\n",
       "       population_log_normalized_yearly  taxpayer_count_log  \\\n",
       "10020                          0.380994            5.535598   \n",
       "10886                          0.394623            5.548094   \n",
       "12596                          0.410692            5.559895   \n",
       "14219                          0.438657            5.581779   \n",
       "15880                          0.463495            5.600679   \n",
       "\n",
       "       taxpayer_count_log_normalized_yearly  taxable_income_log  \\\n",
       "10020                              0.579343            9.497427   \n",
       "10886                              0.593036            9.523310   \n",
       "12596                              0.607849            9.559537   \n",
       "14219                              0.641640            9.615839   \n",
       "15880                              0.672562            9.603127   \n",
       "\n",
       "       taxable_income_log_normalized_yearly  taxable_income_per_taxpayer_log  \\\n",
       "10020                              1.416775                         4.961829   \n",
       "10886                              1.445119                         4.975216   \n",
       "12596                              1.490338                         4.999642   \n",
       "14219                              1.569186                         5.034060   \n",
       "15880                              1.539504                         5.002448   \n",
       "\n",
       "       taxable_income_per_taxpayer_log_normalized_yearly  total_tax_log  \\\n",
       "10020                                           7.516626       8.265799   \n",
       "10886                                           7.684541       8.280672   \n",
       "12596                                           7.906475       8.297020   \n",
       "14219                                           8.218735       8.335433   \n",
       "15880                                           7.945012       8.313316   \n",
       "\n",
       "       total_tax_log_normalized_yearly  new_dwellings_log  \\\n",
       "10020                         1.001951           4.188928   \n",
       "10886                         1.018779           4.150756   \n",
       "12596                         1.035597           3.990339   \n",
       "14219                         1.092918           3.895975   \n",
       "15880                         1.061534           4.064083   \n",
       "\n",
       "       new_dwellings_log_normalized_yearly  existing_dwellings_log  \\\n",
       "10020                             0.953829                5.588160   \n",
       "10886                             0.915407                5.605143   \n",
       "12596                             0.622948                5.620136   \n",
       "14219                             0.506015                5.628256   \n",
       "15880                             0.882594                5.639944   \n",
       "\n",
       "       existing_dwellings_log_normalized_yearly  \\\n",
       "10020                                  0.043625   \n",
       "10886                                  0.069870   \n",
       "12596                                  0.092997   \n",
       "14219                                  0.099687   \n",
       "15880                                  0.116210   \n",
       "\n",
       "       unit_price_median_smoothed_pct_chg_normalized_yearly  \\\n",
       "10020                                           1.197871      \n",
       "10886                                           1.325756      \n",
       "12596                                           0.792784      \n",
       "14219                                           0.999511      \n",
       "15880                                           1.115681      \n",
       "\n",
       "       total_tax_growth_normalized_yearly  \\\n",
       "10020                            1.242587   \n",
       "10886                            0.600536   \n",
       "12596                            0.767911   \n",
       "14219                            2.562201   \n",
       "15880                           -1.299834   \n",
       "\n",
       "       taxable_income_growth_normalized_yearly  \\\n",
       "10020                                 3.332668   \n",
       "10886                                 1.082507   \n",
       "12596                                 1.390629   \n",
       "14219                                 3.308448   \n",
       "15880                                -1.115713   \n",
       "\n",
       "       taxable_income_per_taxpayer_growth_normalized_yearly  \\\n",
       "10020                                           2.801374      \n",
       "10886                                           0.665260      \n",
       "12596                                           1.050529      \n",
       "14219                                           2.268437      \n",
       "15880                                          -2.877245      \n",
       "\n",
       "       net_migration_ratio_normalized_yearly  \\\n",
       "10020                               2.891238   \n",
       "10886                               3.529738   \n",
       "12596                               6.184275   \n",
       "14219                               5.265364   \n",
       "15880                               3.201692   \n",
       "\n",
       "       unit_price_median_smoothed_normalized_yearly  count_normalized_yearly  \\\n",
       "10020                                     16.231302                -0.112194   \n",
       "10886                                     16.441401                -0.162684   \n",
       "12596                                     17.107678                -0.147566   \n",
       "14219                                     18.154210                -0.152671   \n",
       "15880                                     19.194516                -0.267504   \n",
       "\n",
       "       total_traded_area_normalized_yearly  population_normalized_yearly  \\\n",
       "10020                            -0.270920                     -0.141833   \n",
       "10886                            -0.309082                     -0.137364   \n",
       "12596                            -0.301729                     -0.131970   \n",
       "14219                            -0.304405                     -0.122051   \n",
       "15880                            -0.439973                     -0.113077   \n",
       "\n",
       "       taxpayer_count_normalized_yearly  taxable_income_normalized_yearly  \\\n",
       "10020                         -0.066958                          0.498455   \n",
       "10886                         -0.061498                          0.531391   \n",
       "12596                         -0.055703                          0.583629   \n",
       "14219                         -0.041034                          0.687880   \n",
       "15880                         -0.027040                          0.645654   \n",
       "\n",
       "       taxable_income_per_taxpayer_normalized_yearly  \\\n",
       "10020                                      10.691254   \n",
       "10886                                      11.023900   \n",
       "12596                                      11.587289   \n",
       "14219                                      12.233268   \n",
       "15880                                      11.510370   \n",
       "\n",
       "       new_dwellings_normalized_yearly  existing_dwellings_normalized_yearly  \\\n",
       "10020                         0.441195                             -0.015471   \n",
       "10886                         0.386022                             -0.007160   \n",
       "12596                         0.154911                             -0.000265   \n",
       "14219                         0.099425                              0.001371   \n",
       "15880                         0.348051                              0.006594   \n",
       "\n",
       "       total_tax_normalized_yearly  migrations_is_available_normalized_yearly  \\\n",
       "10020                     0.120489                                        0.0   \n",
       "10886                     0.131257                                        0.0   \n",
       "12596                     0.122456                                        0.0   \n",
       "14219                     0.152989                                        0.0   \n",
       "15880                     0.134451                                        0.0   \n",
       "\n",
       "       taxable_income_is_available_normalized_yearly  \\\n",
       "10020                                        0.06613   \n",
       "10886                                        0.06613   \n",
       "12596                                        0.06613   \n",
       "14219                                        0.06613   \n",
       "15880                                        0.06613   \n",
       "\n",
       "       dwellings_is_available_normalized_yearly  \\\n",
       "10020                                  0.836356   \n",
       "10886                                  0.836356   \n",
       "12596                                  0.835103   \n",
       "14219                                  0.835103   \n",
       "15880                                  0.835103   \n",
       "\n",
       "       total_tax_is_available_normalized_yearly  count_scaled  \n",
       "10020                                  0.026948      2.763428  \n",
       "10886                                  0.026948      2.681241  \n",
       "12596                                  0.000000      2.698970  \n",
       "14219                                  0.000000      2.681241  \n",
       "15880                                  0.000000      2.477121  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 3158\n",
    "row = eval_df.iloc[idx]\n",
    "target = row[normalized_metric_pct_chg]\n",
    "area_code, year = row[\"area_code\"], row[\"year\"]\n",
    "window = (\n",
    "    df[\n",
    "        (df[\"area_code\"] == area_code)\n",
    "        & (df[\"year\"] <= year - 2)\n",
    "    ]\n",
    "    .sort_values(by=\"year\")\n",
    "    .tail(5)\n",
    ")\n",
    "print(f\"Target: {target}\")\n",
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_normalize_columns = []\n",
    "\n",
    "normalize_columns = [\n",
    "    metric,\n",
    "    metric_pct_chg,\n",
    "    \"count\",\n",
    "    \"total_traded_area\",\n",
    "    \"population\",\n",
    "    \"taxpayer_count\",\n",
    "    \"taxable_income\",\n",
    "    \"taxable_income_per_taxpayer\",\n",
    "    \"taxable_income_growth\",\n",
    "    \"taxable_income_per_taxpayer_growth\",\n",
    "    \"new_dwellings\",\n",
    "    \"existing_dwellings\",\n",
    "    \"new_dwellings_ratio\",\n",
    "    \"net_migration_ratio\",\n",
    "    \"total_tax\",\n",
    "    \"total_tax_growth\",\n",
    "]\n",
    "\n",
    "maintain_columns = [\n",
    "    metric_pct_chg,\n",
    "    \"years_since_crisis\",\n",
    "    \"migrations_is_available\",\n",
    "    \"taxable_income_is_available\",\n",
    "    \"dwellings_is_available\",\n",
    "    \"total_tax_is_available\",\n",
    "]\n",
    "\n",
    "id_columns = [\n",
    "    \"area_code\",\n",
    "    \"area\",\n",
    "    \"year\",\n",
    "]\n",
    "\n",
    "feature_columns = (\n",
    "    [f\"{column}_log_normalized_yearly\" for column in log_normalize_columns]\n",
    "    + [f\"{column}_normalized_yearly\" for column in normalize_columns]\n",
    "    + maintain_columns\n",
    ")\n",
    "\n",
    "final_columns = id_columns + feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0, 22) (1,) [0.81251324] [2.88081359]\n",
      "1 (0, 22) (1,) [1.02185667] [3.26007139]\n",
      "2 (0, 22) (1,) [-0.21269522] [3.11058971]\n",
      "3 (0, 22) (1,) [-0.74802854] [2.39794001]\n",
      "0 torch.Size([5, 22]) torch.Size([1]) tensor([0.8125]) tensor([2.8808])\n",
      "1 torch.Size([5, 22]) torch.Size([1]) tensor([1.0219]) tensor([3.2601])\n",
      "2 torch.Size([5, 22]) torch.Size([1]) tensor([-0.2127]) tensor([3.1106])\n",
      "3 torch.Size([5, 22]) torch.Size([1]) tensor([-0.7480]) tensor([2.3979])\n"
     ]
    }
   ],
   "source": [
    "time_series_dataset = JapanRETimeSeriesDataset(\n",
    "    df,\n",
    "    train_df,\n",
    "    metrics=[normalized_metric_pct_chg],\n",
    "    weight_column=\"count_scaled\",\n",
    "    feature_columns=feature_columns,\n",
    "    shift=years_ahead\n",
    ")\n",
    "\n",
    "time_series_dataset_transformed = JapanRETimeSeriesDataset(\n",
    "    df,\n",
    "    train_df,\n",
    "    metrics=[normalized_metric_pct_chg],\n",
    "    weight_column=\"count_scaled\",\n",
    "    feature_columns=feature_columns,\n",
    "    transform=transforms.Compose([ToNumpy(), PadAndMask(), ToTensor()]),\n",
    "    shift=years_ahead\n",
    ")\n",
    "\n",
    "for i, sampleX in enumerate(time_series_dataset):\n",
    "    print(\n",
    "        i,\n",
    "        sampleX[\"window\"].shape,\n",
    "        sampleX[\"target\"].shape,\n",
    "        sampleX[\"target\"].values,\n",
    "        sampleX[\"weight\"].values,\n",
    "    )\n",
    "    if i == 3:\n",
    "        break\n",
    "\n",
    "\n",
    "for i, sampleY in enumerate(time_series_dataset_transformed):\n",
    "    print(\n",
    "        i,\n",
    "        sampleY[\"window\"].shape,\n",
    "        sampleY[\"target\"].shape,\n",
    "        sampleY[\"target\"],\n",
    "        sampleY[\"weight\"],\n",
    "    )\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JapanRETimeSeriesDataset(\n",
    "    df,\n",
    "    train_df,\n",
    "    feature_columns=feature_columns,\n",
    "    metrics=[normalized_metric_pct_chg],\n",
    "    weight_column=\"count_scaled\",\n",
    "    transform=transforms.Compose([ToNumpy(), PadAndMask(), ToTensor()]),\n",
    ")\n",
    "eval_dataset = JapanRETimeSeriesDataset(\n",
    "    df,\n",
    "    eval_df,\n",
    "    feature_columns=feature_columns,\n",
    "    metrics=[normalized_metric_pct_chg],\n",
    "    weight_column=\"count_scaled\",\n",
    "    transform=transforms.Compose([ToNumpy(), PadAndMask(), ToTensor()]),\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18826 entries, 0 to 18825\n",
      "Data columns (total 44 columns):\n",
      " #   Column                                                Non-Null Count  Dtype  \n",
      "---  ------                                                --------------  -----  \n",
      " 0   unit_price_median_smoothed_pct_chg                    18826 non-null  float64\n",
      " 1   unit_price_median_smoothed                            18826 non-null  float64\n",
      " 2   unit_price_median                                     18826 non-null  float64\n",
      " 3   year                                                  18826 non-null  int64  \n",
      " 4   years_since_crisis                                    18826 non-null  int64  \n",
      " 5   count                                                 18826 non-null  float64\n",
      " 6   total_traded_area                                     18826 non-null  float64\n",
      " 7   population                                            18826 non-null  float64\n",
      " 8   taxpayer_count                                        18826 non-null  float64\n",
      " 9   taxable_income                                        18826 non-null  float64\n",
      " 10  taxable_income_per_taxpayer                           18826 non-null  float64\n",
      " 11  taxable_income_growth                                 18826 non-null  float64\n",
      " 12  taxable_income_per_taxpayer_growth                    18826 non-null  float64\n",
      " 13  total_tax                                             18826 non-null  float64\n",
      " 14  total_tax_growth                                      18826 non-null  float64\n",
      " 15  new_dwellings                                         18826 non-null  float64\n",
      " 16  existing_dwellings                                    18826 non-null  float64\n",
      " 17  net_migration_ratio                                   18826 non-null  float64\n",
      " 18  new_dwellings_ratio                                   18826 non-null  float64\n",
      " 19  migrations_is_available                               18826 non-null  int64  \n",
      " 20  taxable_income_is_available                           18826 non-null  int64  \n",
      " 21  dwellings_is_available                                18826 non-null  int64  \n",
      " 22  total_tax_is_available                                18826 non-null  int64  \n",
      " 23  area_code                                             18826 non-null  int64  \n",
      " 24  area                                                  18826 non-null  object \n",
      " 25  new_dwellings_ratio_normalized_yearly                 18826 non-null  float64\n",
      " 26  log_new_dwellings_ratio                               18826 non-null  float64\n",
      " 27  log_new_dwellings_ratio_normalized_yearly             18826 non-null  float64\n",
      " 28  unit_price_median_smoothed_normalized_yearly          18826 non-null  float64\n",
      " 29  count_normalized_yearly                               18826 non-null  float64\n",
      " 30  total_traded_area_normalized_yearly                   18826 non-null  float64\n",
      " 31  population_normalized_yearly                          18826 non-null  float64\n",
      " 32  taxpayer_count_normalized_yearly                      18826 non-null  float64\n",
      " 33  taxable_income_normalized_yearly                      18826 non-null  float64\n",
      " 34  taxable_income_per_taxpayer_normalized_yearly         18826 non-null  float64\n",
      " 35  total_tax_normalized_yearly                           18826 non-null  float64\n",
      " 36  new_dwellings_normalized_yearly                       18826 non-null  float64\n",
      " 37  existing_dwellings_normalized_yearly                  18826 non-null  float64\n",
      " 38  unit_price_median_smoothed_pct_chg_normalized_yearly  18826 non-null  float64\n",
      " 39  total_tax_growth_normalized_yearly                    18826 non-null  float64\n",
      " 40  taxable_income_growth_normalized_yearly               18826 non-null  float64\n",
      " 41  taxable_income_per_taxpayer_growth_normalized_yearly  18826 non-null  float64\n",
      " 42  net_migration_ratio_normalized_yearly                 18826 non-null  float64\n",
      " 43  count_scaled                                          18826 non-null  float64\n",
      "dtypes: float64(36), int64(7), object(1)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "# device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(feature_columns)\n",
    "d_model = 256\n",
    "d_hid = 256\n",
    "nlayers = 8\n",
    "nhead = 8\n",
    "dropout = 0\n",
    "enc_dropout = 0\n",
    "\n",
    "model = TimeSeriesTransformerModel(\n",
    "    n_features=n_features,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    d_hid=d_hid,\n",
    "    nlayers=nlayers,\n",
    "    dropout=dropout,\n",
    "    enc_dropout=enc_dropout,\n",
    "    device=device,\n",
    ")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 5, 22]) torch.Size([256, 5]) torch.Size([256, 1]) torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "Loss: 3.3871610164642334\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "mse_loss_weighted = MSELossWeighted().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in eval_dataloader:\n",
    "        window = batch[\"window\"].to(device)\n",
    "        mask = batch[\"mask\"].to(device)\n",
    "        target = batch[\"target\"].to(device)\n",
    "        weight = batch[\"weight\"].to(device)\n",
    "\n",
    "        outputs = model(window, mask)\n",
    "        loss = mse_loss_weighted(outputs, target, weight)\n",
    "\n",
    "        print(\n",
    "            batch[\"window\"].shape,\n",
    "            batch[\"mask\"].shape,\n",
    "            batch[\"target\"].shape,\n",
    "            batch[\"weight\"].shape,\n",
    "        )\n",
    "\n",
    "        print(outputs.shape)\n",
    "        \n",
    "        print(\"Loss:\", loss.item())\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4 # 3e-4\n",
    "weight_decay = 1 # 1\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\", # constant\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "# lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "train_losses, train_r2_scores = [], []\n",
    "eval_losses, eval_r2_scores = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train Loss: 8.8429, Eval Loss: 8.5022\n",
      "Train R^2: -0.0357, Eval R^2: 0.0100\n",
      "Epoch: 1\n",
      "Train Loss: 7.0957, Eval Loss: 12.6887\n",
      "Train R^2: 0.1660, Eval R^2: -0.4529\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 5\u001b[0m     train_loss, train_r2_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_weighted\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m      9\u001b[0m     train_r2_scores\u001b[38;5;241m.\u001b[39mappend(train_r2_score)\n",
      "File \u001b[0;32m~/Desktop/japan_re/jre_utils/engine.py:70\u001b[0m, in \u001b[0;36mtrain_weighted\u001b[0;34m(model, dataloader, optimizer, lr_scheduler, progress_bar, device)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     66\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     67\u001b[0m         k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     68\u001b[0m     }  \u001b[38;5;66;03m# may be faster to move whole dataloader to device at once\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwindow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     loss \u001b[38;5;241m=\u001b[39m mse_loss_weighted(outputs, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     73\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/japan_re/jre_utils/models.py:70\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.forward\u001b[0;34m(self, window, mask)\u001b[0m\n\u001b[1;32m     68\u001b[0m window \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(window)\n\u001b[1;32m     69\u001b[0m window \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(window)\n\u001b[0;32m---> 70\u001b[0m output_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(output_layer, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     72\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(pooled_output)\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/transformer.py:387\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    384\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 387\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    390\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/transformer.py:707\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    705\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/Desktop/japan_re/venv38/lib/python3.8/site-packages/torch/nn/functional.py:5440\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5437\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5438\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5440\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5441\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5443\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# progress_bar = tqdm(range(num_training_steps))\n",
    "progress_bar = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_r2_score = train_weighted(\n",
    "        model, train_dataloader, optimizer, lr_scheduler, progress_bar, device=device\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    train_r2_scores.append(train_r2_score)\n",
    "\n",
    "    eval_loss, eval_r2_score = evaluate_weighted(model, eval_dataloader, device=device)\n",
    "    eval_losses.append(eval_loss)\n",
    "    eval_r2_scores.append(eval_r2_score)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Eval Loss: {eval_loss:.4f}\")\n",
    "    print(f\"Train R^2: {train_r2_score:.4f}, Eval R^2: {eval_r2_score:.4f}\")\n",
    "\n",
    "# progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MSE\n",
    "plt.plot(train_losses, label = \"train\")\n",
    "plt.plot(eval_losses, label = \"eval\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss over epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot R2 scores\n",
    "plt.plot(train_r2_scores, label = \"train\")\n",
    "plt.plot(eval_r2_scores, label = \"eval\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('r2 score')\n",
    "plt.title('r2 scores over epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
